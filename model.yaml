backend: tensorflow
class_name: Model
config:
  input_layers:
  - [embedding_1_input, 0, 0]
  - [embedding_2_input, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: &id001 !!python/tuple [null, 24]
      dtype: float32
      name: embedding_1_input
      sparse: false
    inbound_nodes: []
    name: embedding_1_input
  - class_name: InputLayer
    config:
      batch_input_shape: &id002 !!python/tuple [null, 31]
      dtype: float32
      name: embedding_2_input
      sparse: false
    inbound_nodes: []
    name: embedding_2_input
  - class_name: Embedding
    config:
      activity_regularizer: null
      batch_input_shape: *id001
      dtype: float32
      embeddings_constraint: null
      embeddings_initializer:
        class_name: RandomUniform
        config: {maxval: 0.05, minval: -0.05, seed: null}
      embeddings_regularizer: null
      input_dim: 730
      input_length: 24
      mask_zero: false
      name: embedding_1
      output_dim: 100
      trainable: false
    inbound_nodes:
    - - - embedding_1_input
        - 0
        - 0
        - {}
    name: embedding_1
  - class_name: Embedding
    config:
      activity_regularizer: null
      batch_input_shape: *id002
      dtype: float32
      embeddings_constraint: null
      embeddings_initializer:
        class_name: RandomUniform
        config: {maxval: 0.05, minval: -0.05, seed: null}
      embeddings_regularizer: null
      input_dim: 2798
      input_length: 31
      mask_zero: false
      name: embedding_2
      output_dim: 100
      trainable: false
    inbound_nodes:
    - - - embedding_2_input
        - 0
        - 0
        - {}
    name: embedding_2
  - class_name: LSTM
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: false
      implementation: 1
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
      kernel_regularizer: null
      name: lstm_1
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      return_sequences: false
      return_state: false
      stateful: false
      trainable: true
      unit_forget_bias: true
      units: 100
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - embedding_1
        - 0
        - 0
        - {}
    name: lstm_1
  - class_name: LSTM
    config:
      activation: tanh
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      dropout: 0.0
      go_backwards: false
      implementation: 1
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
      kernel_regularizer: null
      name: lstm_2
      recurrent_activation: hard_sigmoid
      recurrent_constraint: null
      recurrent_dropout: 0.0
      recurrent_initializer:
        class_name: Orthogonal
        config: {gain: 1.0, seed: null}
      recurrent_regularizer: null
      return_sequences: false
      return_state: false
      stateful: false
      trainable: true
      unit_forget_bias: true
      units: 100
      unroll: false
      use_bias: true
    inbound_nodes:
    - - - embedding_2
        - 0
        - 0
        - {}
    name: lstm_2
  - class_name: Concatenate
    config: {axis: -1, name: concatenate_1, trainable: true}
    inbound_nodes:
    - - - lstm_1
        - 0
        - 0
        - &id003 {}
      - - lstm_2
        - 0
        - 0
        - *id003
    name: concatenate_1
  - class_name: Sequential
    config:
      build_input_shape: !!python/tuple [null, 200]
      layers:
      - class_name: Activation
        config: {activation: relu, name: activation_1, trainable: true}
      - class_name: Dense
        config:
          activation: linear
          activity_regularizer: null
          bias_constraint: null
          bias_initializer:
            class_name: Zeros
            config: {}
          bias_regularizer: null
          kernel_constraint: null
          kernel_initializer:
            class_name: VarianceScaling
            config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
          kernel_regularizer: null
          name: dense_1
          trainable: true
          units: 256
          use_bias: true
      - class_name: Activation
        config: {activation: relu, name: activation_2, trainable: true}
      - class_name: Dense
        config:
          activation: linear
          activity_regularizer: null
          bias_constraint: null
          bias_initializer:
            class_name: Zeros
            config: {}
          bias_regularizer: null
          kernel_constraint: null
          kernel_initializer:
            class_name: VarianceScaling
            config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
          kernel_regularizer: null
          name: dense_2
          trainable: true
          units: 4
          use_bias: true
      - class_name: Activation
        config: {activation: softmax, name: activation_3, trainable: true}
      name: sequential_3
    inbound_nodes:
    - - - concatenate_1
        - 0
        - 0
        - {}
    name: sequential_3
  name: model_1
  output_layers:
  - [sequential_3, 1, 0]
keras_version: 2.2.4
